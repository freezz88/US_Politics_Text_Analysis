{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f8992ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\freez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\freez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\freez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        I had the same reasoning when I watch fox news...\n",
      "1             Unethical fucks will always find a loophole.\n",
      "2                                      Failed actual coup.\n",
      "3                   Why is trump even in the news anymore?\n",
      "4                   And it could be my head in a basket...\n",
      "                               ...                        \n",
      "17726            lil'wayne got a pardon and not them ah ah\n",
      "17727    So you think it will be called unconstitutiona...\n",
      "17728    The left of America has out numbered the right...\n",
      "17729    Everyone spread the wordâ€¦I just set fire on water\n",
      "17730    Starting to feel like congress should let DOJ ...\n",
      "Name: body, Length: 17703, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\freez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'III Stemming / Lemmatization - ToDo maybe not necessary with fit_transform'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Import der Bibliotheken'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "# For tokenization - ToDo maybe not necessary with fit_transform\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('wordnet')\n",
    "# For lemmatization - ToDo maybe not necessary with fit_transform\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "# For stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "'''Method for reading data from csv and save as type DataFrame (Pandas)'''\n",
    "'''index column in this special data set is the third column'''\n",
    "def inputData(url):\n",
    "    input_data_csv = pd.read_csv(url,index_col=2)\n",
    "    return input_data_csv\n",
    "    \n",
    "'''Data Input as .csv from github'''\n",
    "'''@param: ?raw=true in url important for using clean original data'''\n",
    "data_url = 'https://github.com/freezz88/US_Politics_Text_Analysis/blob/main/reddit_politics.csv?raw=true'\n",
    "data = inputData(data_url)\n",
    "#print(data)\n",
    "\n",
    "'''Cleaning data'''\n",
    "# delete duplicate reviews - column body\n",
    "data.drop_duplicates(subset='body', inplace=True)\n",
    "# delete reviews without text\n",
    "data.dropna(subset=['body'], inplace=True)\n",
    "# Reset the index after the deletion of rows\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "#print(data.head())\n",
    "\n",
    "'''Filter text for the category comments'''\n",
    "'''Only show the column body, the others doesnt matter'''\n",
    "data_reviews = data['title'] == \"Comment\"\n",
    "filtered_data_list = data[data_reviews]\n",
    "#filtered_dataframe = pd.DataFrame(filtered_data_list)\n",
    "#reviews = filtered_dataframe['body']\n",
    "reviews = filtered_data_list['body']\n",
    "#reviews_string = str(reviews)\n",
    "print(reviews)\n",
    "\n",
    "'''Text Preprocessing'''\n",
    "'''I Tokenization - ToDo maybe not necessary with fit_transform '''\n",
    "'''II Download and definition of stopwords with NLTK - ToDo append new stopwords'''\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words_english = set(stopwords.words('english'))\n",
    "'''III Stemming / Lemmatization - ToDo maybe not necessary with fit_transform'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca604333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e076930",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Implementation in near future'''\n",
    "def calculateBoW():\n",
    "    print(\"Method Test\")\n",
    "\n",
    "def calculateTfidf():\n",
    "    print(\"Method Test\")\n",
    "\n",
    "def calculateCoherenceScore():\n",
    "    print(\"Method Test\")\n",
    "\n",
    "def calculateLSA():\n",
    "    print(\"Method Test\")\n",
    "\n",
    "def calculateLDA():\n",
    "    print(\"Method Test\")\n",
    "\n",
    "def printNLPdata():\n",
    "    print(\"Method Test\")\n",
    "\n",
    "def plotNLPdata():\n",
    "    print(\"Method Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6d00a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
